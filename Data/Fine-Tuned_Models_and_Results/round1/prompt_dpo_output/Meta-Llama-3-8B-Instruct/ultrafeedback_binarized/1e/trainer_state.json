{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.997642530671157,
  "eval_steps": 500,
  "global_step": 162,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.030791436131825837,
      "grad_norm": 1954.5657958984375,
      "learning_rate": 1.9953027957931658e-05,
      "logits/chosen": -1.2265625,
      "logits/rejected": -1.2578125,
      "logps/chosen": -760.0,
      "logps/rejected": -636.0,
      "loss": 18.5555,
      "rewards/accuracies": 0.40625,
      "rewards/chosen": -43.0,
      "rewards/margins": -9.5625,
      "rewards/rejected": -33.25,
      "step": 5
    },
    {
      "epoch": 0.061582872263651674,
      "grad_norm": 1393.8822021484375,
      "learning_rate": 1.9812553106273848e-05,
      "logits/chosen": -1.21875,
      "logits/rejected": -1.265625,
      "logps/chosen": -664.0,
      "logps/rejected": -616.0,
      "loss": 14.7908,
      "rewards/accuracies": 0.41874998807907104,
      "rewards/chosen": -38.0,
      "rewards/margins": -5.375,
      "rewards/rejected": -32.5,
      "step": 10
    },
    {
      "epoch": 0.09237430839547751,
      "grad_norm": 1576.2640380859375,
      "learning_rate": 1.957989512315489e-05,
      "logits/chosen": -1.2421875,
      "logits/rejected": -1.2421875,
      "logps/chosen": -740.0,
      "logps/rejected": -624.0,
      "loss": 17.9224,
      "rewards/accuracies": 0.39375001192092896,
      "rewards/chosen": -41.5,
      "rewards/margins": -8.5,
      "rewards/rejected": -33.25,
      "step": 15
    },
    {
      "epoch": 0.12316574452730335,
      "grad_norm": 1525.8489990234375,
      "learning_rate": 1.9257239692688907e-05,
      "logits/chosen": -1.203125,
      "logits/rejected": -1.2421875,
      "logps/chosen": -688.0,
      "logps/rejected": -616.0,
      "loss": 15.2721,
      "rewards/accuracies": 0.4234375059604645,
      "rewards/chosen": -37.75,
      "rewards/margins": -5.78125,
      "rewards/rejected": -31.875,
      "step": 20
    },
    {
      "epoch": 0.15395718065912917,
      "grad_norm": 1392.49853515625,
      "learning_rate": 1.8847617971766577e-05,
      "logits/chosen": -1.21875,
      "logits/rejected": -1.234375,
      "logps/chosen": -672.0,
      "logps/rejected": -564.0,
      "loss": 15.782,
      "rewards/accuracies": 0.40625,
      "rewards/chosen": -37.0,
      "rewards/margins": -8.25,
      "rewards/rejected": -28.75,
      "step": 25
    },
    {
      "epoch": 0.18474861679095503,
      "grad_norm": 1173.958984375,
      "learning_rate": 1.8354878114129368e-05,
      "logits/chosen": -1.203125,
      "logits/rejected": -1.2265625,
      "logps/chosen": -712.0,
      "logps/rejected": -624.0,
      "loss": 17.4319,
      "rewards/accuracies": 0.4124999940395355,
      "rewards/chosen": -40.0,
      "rewards/margins": -6.9375,
      "rewards/rejected": -33.0,
      "step": 30
    },
    {
      "epoch": 0.21554005292278086,
      "grad_norm": 1435.8251953125,
      "learning_rate": 1.7783649119241603e-05,
      "logits/chosen": -1.1953125,
      "logits/rejected": -1.2109375,
      "logps/chosen": -668.0,
      "logps/rejected": -608.0,
      "loss": 14.8785,
      "rewards/accuracies": 0.4046874940395355,
      "rewards/chosen": -36.5,
      "rewards/margins": -4.65625,
      "rewards/rejected": -31.875,
      "step": 35
    },
    {
      "epoch": 0.2463314890546067,
      "grad_norm": 1014.4225463867188,
      "learning_rate": 1.7139297345578992e-05,
      "logits/chosen": -1.1953125,
      "logits/rejected": -1.21875,
      "logps/chosen": -680.0,
      "logps/rejected": -616.0,
      "loss": 14.9281,
      "rewards/accuracies": 0.40937501192092896,
      "rewards/chosen": -36.75,
      "rewards/margins": -4.96875,
      "rewards/rejected": -31.75,
      "step": 40
    },
    {
      "epoch": 0.2771229251864325,
      "grad_norm": 1262.406982421875,
      "learning_rate": 1.6427876096865394e-05,
      "logits/chosen": -1.1953125,
      "logits/rejected": -1.2109375,
      "logps/chosen": -668.0,
      "logps/rejected": -584.0,
      "loss": 14.9835,
      "rewards/accuracies": 0.4078125059604645,
      "rewards/chosen": -36.5,
      "rewards/margins": -6.78125,
      "rewards/rejected": -29.875,
      "step": 45
    },
    {
      "epoch": 0.30791436131825833,
      "grad_norm": 1156.9871826171875,
      "learning_rate": 1.5656068754865388e-05,
      "logits/chosen": -1.1796875,
      "logits/rejected": -1.203125,
      "logps/chosen": -676.0,
      "logps/rejected": -616.0,
      "loss": 13.7862,
      "rewards/accuracies": 0.4390625059604645,
      "rewards/chosen": -36.25,
      "rewards/margins": -5.28125,
      "rewards/rejected": -30.875,
      "step": 50
    },
    {
      "epoch": 0.3387057974500842,
      "grad_norm": 1281.9041748046875,
      "learning_rate": 1.4831125992966386e-05,
      "logits/chosen": -1.2109375,
      "logits/rejected": -1.234375,
      "logps/chosen": -628.0,
      "logps/rejected": -556.0,
      "loss": 14.1955,
      "rewards/accuracies": 0.37968748807907104,
      "rewards/chosen": -33.75,
      "rewards/margins": -6.21875,
      "rewards/rejected": -27.5,
      "step": 55
    },
    {
      "epoch": 0.36949723358191006,
      "grad_norm": 1171.373779296875,
      "learning_rate": 1.396079766039157e-05,
      "logits/chosen": -1.1484375,
      "logits/rejected": -1.1875,
      "logps/chosen": -708.0,
      "logps/rejected": -572.0,
      "loss": 16.6134,
      "rewards/accuracies": 0.37187498807907104,
      "rewards/chosen": -37.25,
      "rewards/margins": -9.125,
      "rewards/rejected": -28.125,
      "step": 60
    },
    {
      "epoch": 0.4002886697137359,
      "grad_norm": 971.81982421875,
      "learning_rate": 1.3053259976951134e-05,
      "logits/chosen": -1.171875,
      "logits/rejected": -1.2109375,
      "logps/chosen": -720.0,
      "logps/rejected": -620.0,
      "loss": 17.2284,
      "rewards/accuracies": 0.3984375,
      "rewards/chosen": -39.0,
      "rewards/margins": -8.8125,
      "rewards/rejected": -30.25,
      "step": 65
    },
    {
      "epoch": 0.4310801058455617,
      "grad_norm": 1321.17626953125,
      "learning_rate": 1.211703872229411e-05,
      "logits/chosen": -1.1640625,
      "logits/rejected": -1.1953125,
      "logps/chosen": -672.0,
      "logps/rejected": -552.0,
      "loss": 16.3517,
      "rewards/accuracies": 0.3843750059604645,
      "rewards/chosen": -36.25,
      "rewards/margins": -9.4375,
      "rewards/rejected": -26.75,
      "step": 70
    },
    {
      "epoch": 0.46187154197738756,
      "grad_norm": 1239.267578125,
      "learning_rate": 1.1160929141252303e-05,
      "logits/chosen": -1.15625,
      "logits/rejected": -1.203125,
      "logps/chosen": -644.0,
      "logps/rejected": -568.0,
      "loss": 14.3083,
      "rewards/accuracies": 0.41093748807907104,
      "rewards/chosen": -33.75,
      "rewards/margins": -6.28125,
      "rewards/rejected": -27.625,
      "step": 75
    },
    {
      "epoch": 0.4926629781092134,
      "grad_norm": 1173.5281982421875,
      "learning_rate": 1.0193913317718245e-05,
      "logits/chosen": -1.1640625,
      "logits/rejected": -1.203125,
      "logps/chosen": -664.0,
      "logps/rejected": -596.0,
      "loss": 14.7864,
      "rewards/accuracies": 0.4078125059604645,
      "rewards/chosen": -35.75,
      "rewards/margins": -6.84375,
      "rewards/rejected": -28.75,
      "step": 80
    },
    {
      "epoch": 0.5234544142410392,
      "grad_norm": 1115.557861328125,
      "learning_rate": 9.225075793280693e-06,
      "logits/chosen": -1.109375,
      "logits/rejected": -1.1640625,
      "logps/chosen": -648.0,
      "logps/rejected": -560.0,
      "loss": 15.5808,
      "rewards/accuracies": 0.3968749940395355,
      "rewards/chosen": -33.75,
      "rewards/margins": -7.75,
      "rewards/rejected": -26.125,
      "step": 85
    },
    {
      "epoch": 0.554245850372865,
      "grad_norm": 1312.9290771484375,
      "learning_rate": 8.263518223330698e-06,
      "logits/chosen": -1.125,
      "logits/rejected": -1.171875,
      "logps/chosen": -672.0,
      "logps/rejected": -584.0,
      "loss": 14.4382,
      "rewards/accuracies": 0.3968749940395355,
      "rewards/chosen": -35.0,
      "rewards/margins": -6.875,
      "rewards/rejected": -28.0,
      "step": 90
    },
    {
      "epoch": 0.5850372865046909,
      "grad_norm": 1140.58203125,
      "learning_rate": 7.3182738723936255e-06,
      "logits/chosen": -1.125,
      "logits/rejected": -1.1640625,
      "logps/chosen": -644.0,
      "logps/rejected": -552.0,
      "loss": 14.9133,
      "rewards/accuracies": 0.3921875059604645,
      "rewards/chosen": -33.25,
      "rewards/margins": -7.5,
      "rewards/rejected": -25.75,
      "step": 95
    },
    {
      "epoch": 0.6158287226365167,
      "grad_norm": 792.2593994140625,
      "learning_rate": 6.3982227519528986e-06,
      "logits/chosen": -1.1328125,
      "logits/rejected": -1.1484375,
      "logps/chosen": -648.0,
      "logps/rejected": -588.0,
      "loss": 12.8225,
      "rewards/accuracies": 0.43437498807907104,
      "rewards/chosen": -33.5,
      "rewards/margins": -5.46875,
      "rewards/rejected": -28.0,
      "step": 100
    },
    {
      "epoch": 0.6466201587683426,
      "grad_norm": 1428.2783203125,
      "learning_rate": 5.512008197995379e-06,
      "logits/chosen": -1.1328125,
      "logits/rejected": -1.1640625,
      "logps/chosen": -648.0,
      "logps/rejected": -572.0,
      "loss": 14.4949,
      "rewards/accuracies": 0.40937501192092896,
      "rewards/chosen": -34.0,
      "rewards/margins": -6.09375,
      "rewards/rejected": -27.875,
      "step": 105
    },
    {
      "epoch": 0.6774115949001684,
      "grad_norm": 1414.0703125,
      "learning_rate": 4.66795567198309e-06,
      "logits/chosen": -1.140625,
      "logits/rejected": -1.15625,
      "logps/chosen": -636.0,
      "logps/rejected": -536.0,
      "loss": 14.7313,
      "rewards/accuracies": 0.3921875059604645,
      "rewards/chosen": -32.75,
      "rewards/margins": -7.125,
      "rewards/rejected": -25.625,
      "step": 110
    },
    {
      "epoch": 0.7082030310319942,
      "grad_norm": 1198.0543212890625,
      "learning_rate": 3.873994548067972e-06,
      "logits/chosen": -1.109375,
      "logits/rejected": -1.1484375,
      "logps/chosen": -620.0,
      "logps/rejected": -592.0,
      "loss": 11.9481,
      "rewards/accuracies": 0.43437498807907104,
      "rewards/chosen": -31.5,
      "rewards/margins": -2.578125,
      "rewards/rejected": -28.875,
      "step": 115
    },
    {
      "epoch": 0.7389944671638201,
      "grad_norm": 1144.3515625,
      "learning_rate": 3.1375836213126653e-06,
      "logits/chosen": -1.125,
      "logits/rejected": -1.1328125,
      "logps/chosen": -664.0,
      "logps/rejected": -600.0,
      "loss": 13.8309,
      "rewards/accuracies": 0.4234375059604645,
      "rewards/chosen": -33.75,
      "rewards/margins": -4.59375,
      "rewards/rejected": -29.125,
      "step": 120
    },
    {
      "epoch": 0.7697859032956459,
      "grad_norm": 1138.570068359375,
      "learning_rate": 2.4656410367233928e-06,
      "logits/chosen": -1.1328125,
      "logits/rejected": -1.1796875,
      "logps/chosen": -624.0,
      "logps/rejected": -548.0,
      "loss": 12.7016,
      "rewards/accuracies": 0.3843750059604645,
      "rewards/chosen": -31.25,
      "rewards/margins": -5.09375,
      "rewards/rejected": -26.125,
      "step": 125
    },
    {
      "epoch": 0.8005773394274718,
      "grad_norm": 1488.937255859375,
      "learning_rate": 1.8644792973703252e-06,
      "logits/chosen": -1.1328125,
      "logits/rejected": -1.1796875,
      "logps/chosen": -684.0,
      "logps/rejected": -572.0,
      "loss": 16.506,
      "rewards/accuracies": 0.3984375,
      "rewards/chosen": -35.5,
      "rewards/margins": -8.5625,
      "rewards/rejected": -27.0,
      "step": 130
    },
    {
      "epoch": 0.8313687755592976,
      "grad_norm": 1210.318603515625,
      "learning_rate": 1.339745962155613e-06,
      "logits/chosen": -1.125,
      "logits/rejected": -1.171875,
      "logps/chosen": -628.0,
      "logps/rejected": -536.0,
      "loss": 14.5105,
      "rewards/accuracies": 0.40625,
      "rewards/chosen": -32.75,
      "rewards/margins": -7.96875,
      "rewards/rejected": -24.75,
      "step": 135
    },
    {
      "epoch": 0.8621602116911234,
      "grad_norm": 1321.3880615234375,
      "learning_rate": 8.963705903385344e-07,
      "logits/chosen": -1.109375,
      "logits/rejected": -1.140625,
      "logps/chosen": -660.0,
      "logps/rejected": -556.0,
      "loss": 16.2645,
      "rewards/accuracies": 0.3890624940395355,
      "rewards/chosen": -35.75,
      "rewards/margins": -8.125,
      "rewards/rejected": -27.5,
      "step": 140
    },
    {
      "epoch": 0.8929516478229492,
      "grad_norm": 915.17529296875,
      "learning_rate": 5.385184312424973e-07,
      "logits/chosen": -1.1328125,
      "logits/rejected": -1.15625,
      "logps/chosen": -612.0,
      "logps/rejected": -548.0,
      "loss": 13.6869,
      "rewards/accuracies": 0.3921875059604645,
      "rewards/chosen": -32.0,
      "rewards/margins": -5.65625,
      "rewards/rejected": -26.375,
      "step": 145
    },
    {
      "epoch": 0.9237430839547751,
      "grad_norm": 1449.8199462890625,
      "learning_rate": 2.6955129420176193e-07,
      "logits/chosen": -1.1484375,
      "logits/rejected": -1.171875,
      "logps/chosen": -608.0,
      "logps/rejected": -536.0,
      "loss": 14.4706,
      "rewards/accuracies": 0.39375001192092896,
      "rewards/chosen": -31.375,
      "rewards/margins": -6.5,
      "rewards/rejected": -24.875,
      "step": 150
    },
    {
      "epoch": 0.9545345200866009,
      "grad_norm": 1234.6444091796875,
      "learning_rate": 9.199596635154684e-08,
      "logits/chosen": -1.125,
      "logits/rejected": -1.1875,
      "logps/chosen": -644.0,
      "logps/rejected": -548.0,
      "loss": 13.8736,
      "rewards/accuracies": 0.38593751192092896,
      "rewards/chosen": -33.25,
      "rewards/margins": -7.0625,
      "rewards/rejected": -26.125,
      "step": 155
    },
    {
      "epoch": 0.9853259562184268,
      "grad_norm": 1295.3853759765625,
      "learning_rate": 7.520474957699586e-09,
      "logits/chosen": -1.140625,
      "logits/rejected": -1.203125,
      "logps/chosen": -624.0,
      "logps/rejected": -528.0,
      "loss": 14.4322,
      "rewards/accuracies": 0.39531248807907104,
      "rewards/chosen": -31.5,
      "rewards/margins": -6.40625,
      "rewards/rejected": -25.0,
      "step": 160
    },
    {
      "epoch": 0.997642530671157,
      "eval_logits/chosen": -1.1171875,
      "eval_logits/rejected": -1.15625,
      "eval_logps/chosen": -640.0,
      "eval_logps/rejected": -560.0,
      "eval_loss": 14.131305694580078,
      "eval_rewards/accuracies": 0.39649999141693115,
      "eval_rewards/chosen": -33.0,
      "eval_rewards/margins": -6.9375,
      "eval_rewards/rejected": -26.125,
      "eval_runtime": 388.7676,
      "eval_samples_per_second": 5.144,
      "eval_steps_per_second": 5.144,
      "step": 162
    },
    {
      "epoch": 0.997642530671157,
      "step": 162,
      "total_flos": 0.0,
      "train_loss": 15.047650819943275,
      "train_runtime": 8837.1209,
      "train_samples_per_second": 2.352,
      "train_steps_per_second": 0.018
    }
  ],
  "logging_steps": 5,
  "max_steps": 162,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
