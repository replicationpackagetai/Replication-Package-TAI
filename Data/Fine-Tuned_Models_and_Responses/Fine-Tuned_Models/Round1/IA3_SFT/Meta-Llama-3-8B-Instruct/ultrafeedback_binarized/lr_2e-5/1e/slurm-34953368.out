created virtual environment CPython3.11.5.final.0-64 in 1178ms
  creator CPython3Posix(dest=/localscratch/taraghi.34953368.0/LLM, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/taraghi/.local/share/virtualenv)
    added seed packages: pip==24.2, setuptools==73.0.1, wheel==0.44.0
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: pip in /localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages (24.2)
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/accelerate-0.32.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 1))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/aiohttp-3.9.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 2))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/aiosignal-1.3.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/attrs-24.2.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2024.2.2+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.2.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/datasets-2.19.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/dill-0.3.8+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 8))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docstring_parser-0.15+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 9))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.13.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 10))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/frozenlist-1.4.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 11))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2024.3.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 12))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/huggingface_hub-0.24.2+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 13))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.4+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 14))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.4+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 15))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/markdown_it_py-3.0.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 16))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.5+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 17))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/mdurl-0.1.2+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 18))
Requirement already satisfied: mpmath==1.3.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 19)) (1.3.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multidict-6.0.5+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 20))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/multiprocess-0.70.16+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 21))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.3+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 22))
Requirement already satisfied: numpy==1.26.4+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 23)) (1.26.4+computecanada)
Requirement already satisfied: packaging==24.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 24)) (24.1+computecanada)
Requirement already satisfied: pandas==2.2.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 25)) (2.2.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/peft-0.11.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 26))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/protobuf-5.27.2+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 27))
Requirement already satisfied: psutil==5.9.8 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 28)) (5.9.8)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyarrow_hotfix-0.6+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 29))
Requirement already satisfied: python_dateutil==2.9.0.post0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 30)) (2.9.0.post0+computecanada)
Requirement already satisfied: pytz==2024.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 31)) (2024.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/PyYAML-6.0.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 32))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2023.8.8+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 33))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.31.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 34))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rich-13.8.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 35))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/safetensors-0.4.3+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 36))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/sentencepiece-0.2.0+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 37))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/shtab-1.7.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 38))
Requirement already satisfied: six==1.16.0+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 39)) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sympy-1.13.2+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 40))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/tokenizers-0.15.0+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 41))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.3.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 42))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.66.5+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 43))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-4.38.1+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 44))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/trl-0.7.11+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 45))
Requirement already satisfied: typing_extensions==4.12.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 46)) (4.12.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tyro-0.7.3+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 47))
Requirement already satisfied: tzdata==2024.1+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages (from -r peft4-reqs.txt (line 48)) (2024.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.1.0+computecanada-py3-none-any.whl (from -r peft4-reqs.txt (line 49))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/xxhash-3.2.0+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 50))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/yarl-1.9.4+computecanada-cp311-cp311-linux_x86_64.whl (from -r peft4-reqs.txt (line 51))
Requirement already satisfied: pyarrow>=12.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/arrow/17.0.0/lib/python3.11/site-packages (from datasets==2.19.1+computecanada->-r peft4-reqs.txt (line 7)) (17.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024a/lib/python3.11/site-packages (from rich==13.8.0+computecanada->-r peft4-reqs.txt (line 35)) (2.18.0+computecanada)
Installing collected packages: sentencepiece, xxhash, urllib3, tqdm, sympy, shtab, safetensors, regex, PyYAML, pyarrow_hotfix, protobuf, networkx, multidict, mdurl, MarkupSafe, idna, fsspec, frozenlist, filelock, docstring_parser, dill, charset_normalizer, certifi, attrs, yarl, requests, multiprocess, markdown_it_py, jinja2, aiosignal, torch, rich, huggingface_hub, aiohttp, tyro, tokenizers, accelerate, transformers, datasets, trl, peft
  Attempting uninstall: sympy
    Found existing installation: sympy 1.12.1+computecanada
    Not uninstalling sympy at /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages, outside environment /localscratch/taraghi.34953368.0/LLM
    Can't uninstall 'sympy'. No files were found to uninstall.
Successfully installed MarkupSafe-2.1.5+computecanada PyYAML-6.0.1+computecanada accelerate-0.32.1+computecanada aiohttp-3.9.1+computecanada aiosignal-1.3.1+computecanada attrs-24.2.0+computecanada certifi-2024.2.2+computecanada charset_normalizer-3.2.0+computecanada datasets-2.19.1+computecanada dill-0.3.8+computecanada docstring_parser-0.15+computecanada filelock-3.13.1+computecanada frozenlist-1.4.1+computecanada fsspec-2024.3.1+computecanada huggingface_hub-0.24.2+computecanada idna-3.4+computecanada jinja2-3.1.4+computecanada markdown_it_py-3.0.0+computecanada mdurl-0.1.2+computecanada multidict-6.0.5+computecanada multiprocess-0.70.16+computecanada networkx-3.3+computecanada peft-0.11.1+computecanada protobuf-5.27.2+computecanada pyarrow_hotfix-0.6+computecanada regex-2023.8.8+computecanada requests-2.31.0+computecanada rich-13.8.0+computecanada safetensors-0.4.3+computecanada sentencepiece-0.2.0+computecanada shtab-1.7.1+computecanada sympy-1.13.2+computecanada tokenizers-0.15.0+computecanada torch-2.3.1+computecanada tqdm-4.66.5+computecanada transformers-4.38.1+computecanada trl-0.7.11+computecanada tyro-0.7.3+computecanada urllib3-2.1.0+computecanada xxhash-3.2.0+computecanada yarl-1.9.4+computecanada
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
0it [00:00, ?it/s]0it [00:00, ?it/s]
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading Dataset...
Loading Tokenizer...
Processing Dataset...
Applying chat template (num_proc=64):   0%|          | 0/20785 [00:00<?, ? examples/s]Applying chat template (num_proc=64):   0%|          | 1/20785 [00:00<5:38:49,  1.02 examples/s]Applying chat template (num_proc=64):   0%|          | 3/20785 [00:01<1:41:54,  3.40 examples/s]Applying chat template (num_proc=64):   0%|          | 5/20785 [00:01<1:19:47,  4.34 examples/s]Applying chat template (num_proc=64):   0%|          | 6/20785 [00:01<1:18:01,  4.44 examples/s]Applying chat template (num_proc=64):   0%|          | 8/20785 [00:01<57:29,  6.02 examples/s]  Applying chat template (num_proc=64):   0%|          | 13/20785 [00:02<36:45,  9.42 examples/s]Applying chat template (num_proc=64):   0%|          | 18/20785 [00:02<30:49, 11.23 examples/s]Applying chat template (num_proc=64):   0%|          | 20/20785 [00:02<35:54,  9.64 examples/s]Applying chat template (num_proc=64):   0%|          | 27/20785 [00:03<23:34, 14.67 examples/s]Applying chat template (num_proc=64):   0%|          | 41/20785 [00:03<12:15, 28.21 examples/s]Applying chat template (num_proc=64):   0%|          | 53/20785 [00:03<08:31, 40.55 examples/s]Applying chat template (num_proc=64):   0%|          | 72/20785 [00:03<07:06, 48.53 examples/s]Applying chat template (num_proc=64):   0%|          | 91/20785 [00:03<05:05, 67.67 examples/s]Applying chat template (num_proc=64):   1%|          | 176/20785 [00:03<01:41, 202.34 examples/s]Applying chat template (num_proc=64):   1%|          | 208/20785 [00:04<01:47, 192.21 examples/s]Applying chat template (num_proc=64):   3%|▎         | 587/20785 [00:04<00:40, 503.73 examples/s]Applying chat template (num_proc=64):  26%|██▌       | 5424/20785 [00:04<00:02, 6280.94 examples/s]Applying chat template (num_proc=64):  30%|███       | 6284/20785 [00:05<00:02, 5433.35 examples/s]Applying chat template (num_proc=64):  34%|███▎      | 7002/20785 [00:05<00:03, 4418.99 examples/s]Applying chat template (num_proc=64):  37%|███▋      | 7597/20785 [00:05<00:03, 4058.07 examples/s]Applying chat template (num_proc=64):  39%|███▉      | 8122/20785 [00:05<00:04, 3092.13 examples/s]Applying chat template (num_proc=64):  43%|████▎     | 8921/20785 [00:06<00:03, 3393.04 examples/s]Applying chat template (num_proc=64):  45%|████▌     | 9372/20785 [00:06<00:03, 3215.03 examples/s]Applying chat template (num_proc=64):  47%|████▋     | 9751/20785 [00:06<00:04, 2211.09 examples/s]Applying chat template (num_proc=64):  48%|████▊     | 10036/20785 [00:07<00:08, 1265.77 examples/s]Applying chat template (num_proc=64):  53%|█████▎    | 11053/20785 [00:07<00:04, 2081.75 examples/s]Applying chat template (num_proc=64):  55%|█████▌    | 11475/20785 [00:07<00:04, 2208.16 examples/s]Applying chat template (num_proc=64):  57%|█████▋    | 11894/20785 [00:07<00:04, 1946.73 examples/s]Applying chat template (num_proc=64):  59%|█████▉    | 12252/20785 [00:08<00:05, 1543.26 examples/s]Applying chat template (num_proc=64):  64%|██████▍   | 13326/20785 [00:08<00:03, 2226.68 examples/s]Applying chat template (num_proc=64):  66%|██████▌   | 13649/20785 [00:08<00:04, 1723.41 examples/s]Applying chat template (num_proc=64):  68%|██████▊   | 14198/20785 [00:09<00:03, 1896.09 examples/s]Applying chat template (num_proc=64):  72%|███████▏  | 14994/20785 [00:09<00:02, 1941.16 examples/s]Applying chat template (num_proc=64):  73%|███████▎  | 15263/20785 [00:09<00:03, 1593.77 examples/s]Applying chat template (num_proc=64):  78%|███████▊  | 16208/20785 [00:10<00:02, 2156.14 examples/s]Applying chat template (num_proc=64):  81%|████████  | 16876/20785 [00:10<00:01, 2236.86 examples/s]Applying chat template (num_proc=64):  83%|████████▎ | 17269/20785 [00:10<00:01, 2094.04 examples/s]Applying chat template (num_proc=64):  87%|████████▋ | 17985/20785 [00:10<00:01, 2726.64 examples/s]Applying chat template (num_proc=64):  90%|████████▉ | 18702/20785 [00:10<00:00, 3338.19 examples/s]Applying chat template (num_proc=64):  95%|█████████▍| 19690/20785 [00:10<00:00, 4239.24 examples/s]Applying chat template (num_proc=64):  97%|█████████▋| 20228/20785 [00:16<00:01, 400.73 examples/s] Applying chat template (num_proc=64):  99%|█████████▉| 20638/20785 [00:17<00:00, 358.74 examples/s]Applying chat template (num_proc=64): 100%|██████████| 20785/20785 [00:18<00:00, 1148.04 examples/s]
Applying chat template (num_proc=64):   0%|          | 0/1000 [00:00<?, ? examples/s]Applying chat template (num_proc=64):   0%|          | 1/1000 [00:01<21:28,  1.29s/ examples]Applying chat template (num_proc=64):   5%|▍         | 49/1000 [00:01<00:25, 37.76 examples/s]Applying chat template (num_proc=64):   6%|▋         | 65/1000 [00:01<00:21, 42.91 examples/s]Applying chat template (num_proc=64):  10%|▉         | 96/1000 [00:02<00:12, 71.75 examples/s]Applying chat template (num_proc=64):  11%|█         | 112/1000 [00:02<00:11, 79.70 examples/s]Applying chat template (num_proc=64):  13%|█▎        | 129/1000 [00:02<00:10, 79.54 examples/s]Applying chat template (num_proc=64):  16%|█▌        | 161/1000 [00:02<00:12, 69.16 examples/s]Applying chat template (num_proc=64):  22%|██▎       | 225/1000 [00:03<00:09, 78.69 examples/s]Applying chat template (num_proc=64):  29%|██▉       | 288/1000 [00:03<00:05, 124.79 examples/s]Applying chat template (num_proc=64):  32%|███▏      | 320/1000 [00:04<00:06, 99.03 examples/s] Applying chat template (num_proc=64):  35%|███▌      | 353/1000 [00:04<00:06, 102.25 examples/s]Applying chat template (num_proc=64):  37%|███▋      | 369/1000 [00:04<00:06, 96.07 examples/s] Applying chat template (num_proc=64):  42%|████▏     | 417/1000 [00:05<00:06, 92.56 examples/s]Applying chat template (num_proc=64):  43%|████▎     | 433/1000 [00:05<00:06, 89.09 examples/s]Applying chat template (num_proc=64):  45%|████▍     | 449/1000 [00:05<00:06, 87.53 examples/s]Applying chat template (num_proc=64):  50%|████▉     | 497/1000 [00:06<00:04, 110.27 examples/s]Applying chat template (num_proc=64):  53%|█████▎    | 529/1000 [00:06<00:03, 123.85 examples/s]Applying chat template (num_proc=64):  55%|█████▍    | 545/1000 [00:06<00:06, 72.74 examples/s] Applying chat template (num_proc=64):  64%|██████▎   | 636/1000 [00:07<00:03, 115.90 examples/s]Applying chat template (num_proc=64):  67%|██████▋   | 666/1000 [00:07<00:02, 120.95 examples/s]Applying chat template (num_proc=64):  68%|██████▊   | 681/1000 [00:07<00:02, 123.17 examples/s]Applying chat template (num_proc=64):  70%|██████▉   | 696/1000 [00:07<00:02, 113.86 examples/s]Applying chat template (num_proc=64):  71%|███████   | 711/1000 [00:08<00:03, 87.70 examples/s] Applying chat template (num_proc=64):  73%|███████▎  | 727/1000 [00:08<00:03, 89.82 examples/s]Applying chat template (num_proc=64):  74%|███████▍  | 744/1000 [00:08<00:02, 90.74 examples/s]Applying chat template (num_proc=64):  76%|███████▌  | 759/1000 [00:08<00:02, 100.15 examples/s]Applying chat template (num_proc=64):  79%|███████▉  | 788/1000 [00:08<00:01, 114.96 examples/s]Applying chat template (num_proc=64):  82%|████████▏ | 818/1000 [00:08<00:01, 144.96 examples/s]Applying chat template (num_proc=64):  85%|████████▍ | 849/1000 [00:09<00:01, 106.00 examples/s]Applying chat template (num_proc=64):  90%|████████▉ | 896/1000 [00:09<00:00, 144.30 examples/s]Applying chat template (num_proc=64):  93%|█████████▎| 926/1000 [00:09<00:00, 163.59 examples/s]Applying chat template (num_proc=64):  96%|█████████▌| 955/1000 [00:09<00:00, 174.95 examples/s]Applying chat template (num_proc=64):  98%|█████████▊| 985/1000 [00:10<00:00, 105.48 examples/s]Applying chat template (num_proc=64): 100%|██████████| 1000/1000 [00:12<00:00, 82.52 examples/s]
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Sample 4971 of the processed training set:

<|begin_of_text|><|start_header_id|>system<|end_header_id|>

<|eot_id|><|start_header_id|>user<|end_header_id|>

Find pivot index

Given an array of integers nums, calculate the pivot index of this array.

The pivot index is the index where the sum of all the numbers strictly to the left of the index is equal to the sum of all the numbers strictly to the index's right.

If the index is on the left edge of the array, then the left sum is 0 because there are no elements to the left. This also applies to the right edge of the array.

Return the leftmost pivot index. If no such index exists, return -1

/\*\*
 \* @param {number[]} nums
 \* @return {number}
 \*/
var pivotIndex = function(nums) {
 
};<|eot_id|><|start_header_id|>assistant<|end_header_id|>

Sure, I'd be happy to help you with that! The problem you're describing is a classic problem in computer science, known as the "pivot index" problem. The solution is as follows:

1. Start by initializing two variables, `leftSum` and `rightSum`, to 0.
2. Iterate through the array `nums` from left to right.
3. For each element `nums[i]`, calculate the sum of all elements strictly to the left of it (i.e., `leftSum += nums[i-1]` if `i` is not 0, and `leftSum += 0` if `i` is 0).
4. Calculate the sum of all elements strictly to the right of it (i.e., `rightSum += nums[i+1]` if `i` is not the last index, and `rightSum += 0` if `i` is the last index).
5. Check if the sum of the elements strictly to the left of `nums[i]` is equal to the sum of the elements strictly to the right of `nums[i]`. If this condition is satisfied, return `i` as the pivot index.
6. If no such index exists, return -1.

Here's some sample code to illustrate the solution:
```
function pivotIndex(nums) {
  let leftSum = 0;
  let rightSum = 0;
  for (let i = 0; i < nums.length; i++) {
    leftSum += (i > 0 ? nums[i - 1] : 0);
    rightSum += (i < nums.length - 1 ? nums[i + 1] : 0);
    if (leftSum === rightSum) {
      return i;
    }
  }
  return -1;
}
```
The time complexity of this solution is O(n), where n is the length of the input array, and the space complexity is O(1) since we only need to keep track of two variables.

I hope this helps! Let me know if you have any further questions.<|eot_id|>
Sample 752 of the processed training set:

<|begin_of_text|><|start_header_id|>system<|end_header_id|>

<|eot_id|><|start_header_id|>user<|end_header_id|>

Premise: "A man wearing slacks and a red shirt dances with a woman wearing a tight red dress."
Hypothesis: "A man and a woman are sitting down."
Do we know that the hypothesis entailed by the premise? Now, let's be accurate as possible. Some thinking first:<|eot_id|><|start_header_id|>assistant<|end_header_id|>

The hypothesis is not entailed by the premise.

Confidence: 95%<|eot_id|>
Sample 18143 of the processed training set:

<|begin_of_text|><|start_header_id|>system<|end_header_id|>

<|eot_id|><|start_header_id|>user<|end_header_id|>

What environmental, social, and governance (ESG) factors will Six Flags consider when entering new markets?<|eot_id|><|start_header_id|>assistant<|end_header_id|>

Six Flags will consider the following environmental, social, and governance (ESG) factors when entering new markets:

* **Environmental**
    * Air quality: Six Flags will consider the air quality in the new market and ensure that its operations do not contribute to air pollution.
    * Water quality: Six Flags will ensure that its operations do not pollute water sources.
    * Waste management: Six Flags will implement waste management practices to reduce, reuse, and recycle.
    * Energy efficiency: Six Flags will use energy-efficient technologies to reduce its environmental impact.
* **Social**
    * Employment practices: Six Flags will ensure that it complies with all applicable employment laws and regulations in the new market.
    * Community relations: Six Flags will work with the community to ensure that its operations are beneficial and do not cause any harm.
    * Diversity and inclusion: Six Flags will promote diversity and inclusion in its workforce.
* **Governance**
    * Corporate governance: Six Flags will have a strong corporate governance structure in place to ensure that its operations are ethical and responsible.
    * Transparency: Six Flags will be transparent about its operations and financial performance.
    * Risk management: Six Flags will have a robust risk management system in place to identify and mitigate potential risks.

These are just some of the ESG factors that Six Flags will consider when entering new markets. By considering these factors, Six Flags can help to ensure that its operations are sustainable and responsible.<|eot_id|>
Loading Configs...
IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback
*******************************************************************
Output directory set to: IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback
Loading Model....
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 4960.74it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:08<00:26,  8.81s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:17<00:17,  8.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:25<00:08,  8.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  5.97s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.94s/it]
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:161: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
Initializing the Trainer...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 5287.49it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.00s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.40it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
Generating train split: 0 examples [00:00, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2052 > 2048). Running this sequence through the model will result in indexing errors
Generating train split: 1 examples [00:02,  2.64s/ examples]Generating train split: 540 examples [00:02, 276.63 examples/s]Generating train split: 982 examples [00:05, 198.51 examples/s]Generating train split: 1262 examples [00:05, 285.14 examples/s]Generating train split: 1544 examples [00:08, 181.50 examples/s]Generating train split: 2000 examples [00:08, 301.97 examples/s]Generating train split: 2315 examples [00:11, 189.76 examples/s]Generating train split: 2775 examples [00:11, 299.19 examples/s]Generating train split: 3088 examples [00:14, 203.78 examples/s]Generating train split: 3621 examples [00:14, 329.59 examples/s]Generating train split: 4000 examples [00:17, 242.82 examples/s]Generating train split: 4443 examples [00:17, 350.11 examples/s]Generating train split: 4551 examples [00:17, 260.64 examples/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1 examples [00:00,  1.33 examples/s]Generating train split: 220 examples [00:00, 267.99 examples/s]
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
***** Running training *****
  Num examples = 4,551
  Num Epochs = 1
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 128
  Gradient Accumulation steps = 128
  Total optimization steps = 35
  Number of trainable parameters = 524,288
Training...
  0%|          | 0/35 [00:00<?, ?it/s]  3%|▎         | 1/35 [01:30<51:08, 90.26s/it]  6%|▌         | 2/35 [03:00<49:38, 90.26s/it]  9%|▊         | 3/35 [04:30<48:06, 90.21s/it] 11%|█▏        | 4/35 [06:00<46:36, 90.23s/it] 14%|█▍        | 5/35 [07:31<45:06, 90.23s/it]                                               14%|█▍        | 5/35 [07:31<45:06, 90.23s/it] 17%|█▋        | 6/35 [09:01<43:37, 90.26s/it] 20%|██        | 7/35 [10:31<42:08, 90.29s/it] 23%|██▎       | 8/35 [12:02<40:37, 90.29s/it] 26%|██▌       | 9/35 [13:32<39:07, 90.29s/it] 29%|██▊       | 10/35 [15:02<37:37, 90.29s/it]                                                29%|██▊       | 10/35 [15:02<37:37, 90.29s/it] 31%|███▏      | 11/35 [16:33<36:07, 90.32s/it] 34%|███▍      | 12/35 [18:03<34:37, 90.32s/it] 37%|███▋      | 13/35 [19:33<33:06, 90.29s/it] 40%|████      | 14/35 [21:04<31:36, 90.32s/it] 43%|████▎     | 15/35 [22:34<30:06, 90.34s/it]                                                43%|████▎     | 15/35 [22:34<30:06, 90.34s/it] 46%|████▌     | 16/35 [24:04<28:35, 90.30s/it] 49%|████▊     | 17/35 [25:35<27:05, 90.33s/it] 51%|█████▏    | 18/35 [27:05<25:35, 90.34s/it] 54%|█████▍    | 19/35 [28:35<24:05, 90.32s/it] 57%|█████▋    | 20/35 [30:05<22:34, 90.31s/it]                                                57%|█████▋    | 20/35 [30:05<22:34, 90.31s/it] 60%|██████    | 21/35 [31:36<21:04, 90.33s/it] 63%|██████▎   | 22/35 [33:06<19:34, 90.31s/it] 66%|██████▌   | 23/35 [34:36<18:03, 90.32s/it] 69%|██████▊   | 24/35 [36:07<16:33, 90.32s/it] 71%|███████▏  | 25/35 [37:37<15:03, 90.34s/it]                                                71%|███████▏  | 25/35 [37:37<15:03, 90.34s/it] 74%|███████▍  | 26/35 [39:07<13:32, 90.31s/it] 77%|███████▋  | 27/35 [40:38<12:02, 90.31s/it] 80%|████████  | 28/35 [42:08<10:32, 90.30s/it] 83%|████████▎ | 29/35 [43:38<09:01, 90.30s/it] 86%|████████▌ | 30/35 [45:09<07:31, 90.30s/it]                                                86%|████████▌ | 30/35 [45:09<07:31, 90.30s/it] 89%|████████▊ | 31/35 [46:39<06:01, 90.31s/it] 91%|█████████▏| 32/35 [48:09<04:30, 90.29s/it] 94%|█████████▍| 33/35 [49:40<03:00, 90.31s/it] 97%|█████████▋| 34/35 [51:10<01:30, 90.36s/it]100%|██████████| 35/35 [52:40<00:00, 90.37s/it]                                               100%|██████████| 35/35 [52:40<00:00, 90.37s/it]***** Running Evaluation *****
  Num examples = 220
  Batch size = 1
{'loss': 1.8727, 'grad_norm': 0.3552626073360443, 'learning_rate': 1.900968867902419e-05, 'epoch': 0.14}
{'loss': 1.8944, 'grad_norm': 0.3560824990272522, 'learning_rate': 1.6234898018587336e-05, 'epoch': 0.28}
{'loss': 1.877, 'grad_norm': 0.353782594203949, 'learning_rate': 1.2225209339563144e-05, 'epoch': 0.42}
{'loss': 1.9028, 'grad_norm': 0.36584222316741943, 'learning_rate': 7.774790660436857e-06, 'epoch': 0.56}
{'loss': 1.9095, 'grad_norm': 0.356060653924942, 'learning_rate': 3.7651019814126656e-06, 'epoch': 0.7}
{'loss': 1.9068, 'grad_norm': 0.3804774284362793, 'learning_rate': 9.903113209758098e-07, 'epoch': 0.84}
{'loss': 1.8898, 'grad_norm': 0.3664577305316925, 'learning_rate': 0.0, 'epoch': 0.98}

  0%|          | 0/220 [00:00<?, ?it/s][A
  1%|          | 2/220 [00:00<00:23,  9.09it/s][A
  1%|▏         | 3/220 [00:00<00:33,  6.41it/s][A
  2%|▏         | 4/220 [00:00<00:38,  5.55it/s][A
  2%|▏         | 5/220 [00:00<00:41,  5.14it/s][A
  3%|▎         | 6/220 [00:01<00:43,  4.92it/s][A
  3%|▎         | 7/220 [00:01<00:44,  4.79it/s][A
  4%|▎         | 8/220 [00:01<00:45,  4.69it/s][A
  4%|▍         | 9/220 [00:01<00:45,  4.63it/s][A
  5%|▍         | 10/220 [00:01<00:45,  4.59it/s][A
  5%|▌         | 11/220 [00:02<00:45,  4.57it/s][A
  5%|▌         | 12/220 [00:02<00:45,  4.55it/s][A
  6%|▌         | 13/220 [00:02<00:45,  4.54it/s][A
  6%|▋         | 14/220 [00:02<00:45,  4.54it/s][A
  7%|▋         | 15/220 [00:03<00:45,  4.53it/s][A
  7%|▋         | 16/220 [00:03<00:44,  4.53it/s][A
  8%|▊         | 17/220 [00:03<00:44,  4.54it/s][A
  8%|▊         | 18/220 [00:03<00:44,  4.54it/s][A
  9%|▊         | 19/220 [00:03<00:44,  4.53it/s][A
  9%|▉         | 20/220 [00:04<00:44,  4.53it/s][A
 10%|▉         | 21/220 [00:04<00:43,  4.52it/s][A
 10%|█         | 22/220 [00:04<00:43,  4.53it/s][A
 10%|█         | 23/220 [00:04<00:43,  4.52it/s][A
 11%|█         | 24/220 [00:05<00:43,  4.51it/s][A
 11%|█▏        | 25/220 [00:05<00:43,  4.51it/s][A
 12%|█▏        | 26/220 [00:05<00:43,  4.51it/s][A
 12%|█▏        | 27/220 [00:05<00:42,  4.51it/s][A
 13%|█▎        | 28/220 [00:05<00:42,  4.51it/s][A
 13%|█▎        | 29/220 [00:06<00:42,  4.52it/s][A
 14%|█▎        | 30/220 [00:06<00:42,  4.52it/s][A
 14%|█▍        | 31/220 [00:06<00:41,  4.53it/s][A
 15%|█▍        | 32/220 [00:06<00:41,  4.53it/s][A
 15%|█▌        | 33/220 [00:07<00:41,  4.53it/s][A
 15%|█▌        | 34/220 [00:07<00:41,  4.53it/s][A
 16%|█▌        | 35/220 [00:07<00:40,  4.53it/s][A
 16%|█▋        | 36/220 [00:07<00:40,  4.53it/s][A
 17%|█▋        | 37/220 [00:07<00:40,  4.52it/s][A
 17%|█▋        | 38/220 [00:08<00:40,  4.52it/s][A
 18%|█▊        | 39/220 [00:08<00:40,  4.51it/s][A
 18%|█▊        | 40/220 [00:08<00:39,  4.51it/s][A
 19%|█▊        | 41/220 [00:08<00:39,  4.51it/s][A
 19%|█▉        | 42/220 [00:09<00:39,  4.51it/s][A
 20%|█▉        | 43/220 [00:09<00:39,  4.51it/s][A
 20%|██        | 44/220 [00:09<00:38,  4.51it/s][A
 20%|██        | 45/220 [00:09<00:38,  4.52it/s][A
 21%|██        | 46/220 [00:09<00:38,  4.53it/s][A
 21%|██▏       | 47/220 [00:10<00:38,  4.53it/s][A
 22%|██▏       | 48/220 [00:10<00:37,  4.53it/s][A
 22%|██▏       | 49/220 [00:10<00:37,  4.53it/s][A
 23%|██▎       | 50/220 [00:10<00:37,  4.52it/s][A
 23%|██▎       | 51/220 [00:11<00:37,  4.53it/s][A
 24%|██▎       | 52/220 [00:11<00:37,  4.52it/s][A
 24%|██▍       | 53/220 [00:11<00:36,  4.52it/s][A
 25%|██▍       | 54/220 [00:11<00:36,  4.51it/s][A
 25%|██▌       | 55/220 [00:11<00:36,  4.51it/s][A
 25%|██▌       | 56/220 [00:12<00:36,  4.51it/s][A
 26%|██▌       | 57/220 [00:12<00:36,  4.52it/s][A
 26%|██▋       | 58/220 [00:12<00:35,  4.52it/s][A
 27%|██▋       | 59/220 [00:12<00:35,  4.53it/s][A
 27%|██▋       | 60/220 [00:13<00:35,  4.53it/s][A
 28%|██▊       | 61/220 [00:13<00:35,  4.53it/s][A
 28%|██▊       | 62/220 [00:13<00:34,  4.53it/s][A
 29%|██▊       | 63/220 [00:13<00:34,  4.53it/s][A
 29%|██▉       | 64/220 [00:13<00:34,  4.53it/s][A
 30%|██▉       | 65/220 [00:14<00:34,  4.52it/s][A
 30%|███       | 66/220 [00:14<00:34,  4.52it/s][A
 30%|███       | 67/220 [00:14<00:33,  4.51it/s][A
 31%|███       | 68/220 [00:14<00:33,  4.51it/s][A
 31%|███▏      | 69/220 [00:15<00:33,  4.51it/s][A
 32%|███▏      | 70/220 [00:15<00:33,  4.51it/s][A
 32%|███▏      | 71/220 [00:15<00:33,  4.51it/s][A
 33%|███▎      | 72/220 [00:15<00:32,  4.52it/s][A
 33%|███▎      | 73/220 [00:15<00:32,  4.52it/s][A
 34%|███▎      | 74/220 [00:16<00:32,  4.53it/s][A
 34%|███▍      | 75/220 [00:16<00:32,  4.53it/s][A
 35%|███▍      | 76/220 [00:16<00:31,  4.53it/s][A
 35%|███▌      | 77/220 [00:16<00:31,  4.53it/s][A
 35%|███▌      | 78/220 [00:17<00:31,  4.53it/s][A
 36%|███▌      | 79/220 [00:17<00:31,  4.52it/s][A
 36%|███▋      | 80/220 [00:17<00:30,  4.52it/s][A
 37%|███▋      | 81/220 [00:17<00:30,  4.52it/s][A
 37%|███▋      | 82/220 [00:17<00:30,  4.51it/s][A
 38%|███▊      | 83/220 [00:18<00:30,  4.50it/s][A
 38%|███▊      | 84/220 [00:18<00:30,  4.51it/s][A
 39%|███▊      | 85/220 [00:18<00:29,  4.51it/s][A
 39%|███▉      | 86/220 [00:18<00:29,  4.51it/s][A
 40%|███▉      | 87/220 [00:19<00:29,  4.51it/s][A
 40%|████      | 88/220 [00:19<00:29,  4.51it/s][A
 40%|████      | 89/220 [00:19<00:28,  4.52it/s][A
 41%|████      | 90/220 [00:19<00:28,  4.52it/s][A
 41%|████▏     | 91/220 [00:19<00:28,  4.52it/s][A
 42%|████▏     | 92/220 [00:20<00:28,  4.53it/s][A
 42%|████▏     | 93/220 [00:20<00:28,  4.53it/s][A
 43%|████▎     | 94/220 [00:20<00:27,  4.53it/s][A
 43%|████▎     | 95/220 [00:20<00:27,  4.53it/s][A
 44%|████▎     | 96/220 [00:21<00:27,  4.52it/s][A
 44%|████▍     | 97/220 [00:21<00:27,  4.52it/s][A
 45%|████▍     | 98/220 [00:21<00:27,  4.51it/s][A
 45%|████▌     | 99/220 [00:21<00:26,  4.51it/s][A
 45%|████▌     | 100/220 [00:21<00:26,  4.51it/s][A
 46%|████▌     | 101/220 [00:22<00:26,  4.51it/s][A
 46%|████▋     | 102/220 [00:22<00:26,  4.51it/s][A
 47%|████▋     | 103/220 [00:22<00:25,  4.51it/s][A
 47%|████▋     | 104/220 [00:22<00:25,  4.51it/s][A
 48%|████▊     | 105/220 [00:23<00:25,  4.52it/s][A
 48%|████▊     | 106/220 [00:23<00:25,  4.52it/s][A
 49%|████▊     | 107/220 [00:23<00:24,  4.52it/s][A
 49%|████▉     | 108/220 [00:23<00:24,  4.53it/s][A
 50%|████▉     | 109/220 [00:23<00:24,  4.53it/s][A
 50%|█████     | 110/220 [00:24<00:24,  4.53it/s][A
 50%|█████     | 111/220 [00:24<00:24,  4.53it/s][A
 51%|█████     | 112/220 [00:24<00:23,  4.53it/s][A
 51%|█████▏    | 113/220 [00:24<00:23,  4.53it/s][A
 52%|█████▏    | 114/220 [00:24<00:23,  4.52it/s][A
 52%|█████▏    | 115/220 [00:25<00:23,  4.51it/s][A
 53%|█████▎    | 116/220 [00:25<00:23,  4.51it/s][A
 53%|█████▎    | 117/220 [00:25<00:22,  4.51it/s][A
 54%|█████▎    | 118/220 [00:25<00:22,  4.51it/s][A
 54%|█████▍    | 119/220 [00:26<00:22,  4.52it/s][A
 55%|█████▍    | 120/220 [00:26<00:22,  4.52it/s][A
 55%|█████▌    | 121/220 [00:26<00:21,  4.52it/s][A
 55%|█████▌    | 122/220 [00:26<00:21,  4.53it/s][A
 56%|█████▌    | 123/220 [00:26<00:21,  4.53it/s][A
 56%|█████▋    | 124/220 [00:27<00:21,  4.53it/s][A
 57%|█████▋    | 125/220 [00:27<00:20,  4.53it/s][A
 57%|█████▋    | 126/220 [00:27<00:20,  4.52it/s][A
 58%|█████▊    | 127/220 [00:27<00:20,  4.52it/s][A
 58%|█████▊    | 128/220 [00:28<00:20,  4.52it/s][A
 59%|█████▊    | 129/220 [00:28<00:20,  4.51it/s][A
 59%|█████▉    | 130/220 [00:28<00:19,  4.51it/s][A
 60%|█████▉    | 131/220 [00:28<00:19,  4.51it/s][A
 60%|██████    | 132/220 [00:28<00:19,  4.52it/s][A
 60%|██████    | 133/220 [00:29<00:19,  4.52it/s][A
 61%|██████    | 134/220 [00:29<00:18,  4.53it/s][A
 61%|██████▏   | 135/220 [00:29<00:18,  4.53it/s][A
 62%|██████▏   | 136/220 [00:29<00:18,  4.53it/s][A
 62%|██████▏   | 137/220 [00:30<00:18,  4.53it/s][A
 63%|██████▎   | 138/220 [00:30<00:18,  4.53it/s][A
 63%|██████▎   | 139/220 [00:30<00:17,  4.52it/s][A
 64%|██████▎   | 140/220 [00:30<00:17,  4.52it/s][A
 64%|██████▍   | 141/220 [00:30<00:17,  4.51it/s][A
 65%|██████▍   | 142/220 [00:31<00:17,  4.51it/s][A
 65%|██████▌   | 143/220 [00:31<00:17,  4.51it/s][A
 65%|██████▌   | 144/220 [00:31<00:16,  4.51it/s][A
 66%|██████▌   | 145/220 [00:31<00:16,  4.51it/s][A
 66%|██████▋   | 146/220 [00:32<00:16,  4.51it/s][A
 67%|██████▋   | 147/220 [00:32<00:16,  4.51it/s][A
 67%|██████▋   | 148/220 [00:32<00:15,  4.52it/s][A
 68%|██████▊   | 149/220 [00:32<00:15,  4.53it/s][A
 68%|██████▊   | 150/220 [00:32<00:15,  4.53it/s][A
 69%|██████▊   | 151/220 [00:33<00:15,  4.53it/s][A
 69%|██████▉   | 152/220 [00:33<00:15,  4.53it/s][A
 70%|██████▉   | 153/220 [00:33<00:14,  4.53it/s][A
 70%|███████   | 154/220 [00:33<00:14,  4.52it/s][A
 70%|███████   | 155/220 [00:34<00:14,  4.52it/s][A
 71%|███████   | 156/220 [00:34<00:14,  4.52it/s][A
 71%|███████▏  | 157/220 [00:34<00:13,  4.52it/s][A
 72%|███████▏  | 158/220 [00:34<00:13,  4.52it/s][A
 72%|███████▏  | 159/220 [00:34<00:13,  4.51it/s][A
 73%|███████▎  | 160/220 [00:35<00:13,  4.51it/s][A
 73%|███████▎  | 161/220 [00:35<00:13,  4.51it/s][A
 74%|███████▎  | 162/220 [00:35<00:12,  4.51it/s][A
 74%|███████▍  | 163/220 [00:35<00:12,  4.51it/s][A
 75%|███████▍  | 164/220 [00:36<00:12,  4.52it/s][A
 75%|███████▌  | 165/220 [00:36<00:12,  4.52it/s][A
 75%|███████▌  | 166/220 [00:36<00:11,  4.52it/s][A
 76%|███████▌  | 167/220 [00:36<00:11,  4.52it/s][A
 76%|███████▋  | 168/220 [00:36<00:11,  4.52it/s][A
 77%|███████▋  | 169/220 [00:37<00:11,  4.52it/s][A
 77%|███████▋  | 170/220 [00:37<00:11,  4.52it/s][A
 78%|███████▊  | 171/220 [00:37<00:10,  4.52it/s][A
 78%|███████▊  | 172/220 [00:37<00:10,  4.52it/s][A
 79%|███████▊  | 173/220 [00:38<00:10,  4.52it/s][A
 79%|███████▉  | 174/220 [00:38<00:10,  4.51it/s][A
 80%|███████▉  | 175/220 [00:38<00:09,  4.51it/s][A
 80%|████████  | 176/220 [00:38<00:09,  4.51it/s][A
 80%|████████  | 177/220 [00:38<00:09,  4.51it/s][A
 81%|████████  | 178/220 [00:39<00:09,  4.51it/s][A
 81%|████████▏ | 179/220 [00:39<00:09,  4.51it/s][A
 82%|████████▏ | 180/220 [00:39<00:08,  4.51it/s][A
 82%|████████▏ | 181/220 [00:39<00:08,  4.52it/s][A
 83%|████████▎ | 182/220 [00:40<00:08,  4.53it/s][A
 83%|████████▎ | 183/220 [00:40<00:08,  4.53it/s][A
 84%|████████▎ | 184/220 [00:40<00:07,  4.53it/s][A
 84%|████████▍ | 185/220 [00:40<00:07,  4.53it/s][A
 85%|████████▍ | 186/220 [00:40<00:07,  4.53it/s][A
 85%|████████▌ | 187/220 [00:41<00:07,  4.52it/s][A
 85%|████████▌ | 188/220 [00:41<00:07,  4.52it/s][A
 86%|████████▌ | 189/220 [00:41<00:06,  4.52it/s][A
 86%|████████▋ | 190/220 [00:41<00:06,  4.51it/s][A
 87%|████████▋ | 191/220 [00:42<00:06,  4.51it/s][A
 87%|████████▋ | 192/220 [00:42<00:06,  4.51it/s][A
 88%|████████▊ | 193/220 [00:42<00:05,  4.51it/s][A
 88%|████████▊ | 194/220 [00:42<00:05,  4.51it/s][A
 89%|████████▊ | 195/220 [00:42<00:05,  4.52it/s][A
 89%|████████▉ | 196/220 [00:43<00:05,  4.52it/s][A
 90%|████████▉ | 197/220 [00:43<00:05,  4.52it/s][A
 90%|█████████ | 198/220 [00:43<00:04,  4.53it/s][A
 90%|█████████ | 199/220 [00:43<00:04,  4.53it/s][A
 91%|█████████ | 200/220 [00:44<00:04,  4.53it/s][A
 91%|█████████▏| 201/220 [00:44<00:04,  4.53it/s][A
 92%|█████████▏| 202/220 [00:44<00:03,  4.53it/s][A
 92%|█████████▏| 203/220 [00:44<00:03,  4.52it/s][A
 93%|█████████▎| 204/220 [00:44<00:03,  4.52it/s][A
 93%|█████████▎| 205/220 [00:45<00:03,  4.51it/s][A
 94%|█████████▎| 206/220 [00:45<00:03,  4.51it/s][A
 94%|█████████▍| 207/220 [00:45<00:02,  4.51it/s][A
 95%|█████████▍| 208/220 [00:45<00:02,  4.52it/s][A
 95%|█████████▌| 209/220 [00:46<00:02,  4.52it/s][A
 95%|█████████▌| 210/220 [00:46<00:02,  4.52it/s][A
 96%|█████████▌| 211/220 [00:46<00:01,  4.52it/s][A
 96%|█████████▋| 212/220 [00:46<00:01,  4.53it/s][A
 97%|█████████▋| 213/220 [00:46<00:01,  4.53it/s][A
 97%|█████████▋| 214/220 [00:47<00:01,  4.53it/s][A
 98%|█████████▊| 215/220 [00:47<00:01,  4.53it/s][A
 98%|█████████▊| 216/220 [00:47<00:00,  4.52it/s][A
 99%|█████████▊| 217/220 [00:47<00:00,  4.52it/s][A
 99%|█████████▉| 218/220 [00:48<00:00,  4.52it/s][A
100%|█████████▉| 219/220 [00:48<00:00,  4.51it/s][A
100%|██████████| 220/220 [00:48<00:00,  4.52it/s][A                                               
                                                 [A100%|██████████| 35/35 [53:29<00:00, 90.37s/it]
100%|██████████| 220/220 [00:48<00:00,  4.52it/s][A
                                                 [A

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|██████████| 35/35 [53:29<00:00, 90.37s/it]100%|██████████| 35/35 [53:29<00:00, 91.70s/it]
Saving model checkpoint to IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1549008e4250>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"), '(Request ID: 38a9d21c-8153-4115-b2dd-4c739be8be2c)') - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.
  warnings.warn(
/localscratch/taraghi.34953368.0/LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
tokenizer config file saved in IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback/tokenizer_config.json
Special tokens file saved in IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback/special_tokens_map.json
{'eval_loss': 1.8570090532302856, 'eval_runtime': 48.6769, 'eval_samples_per_second': 4.52, 'eval_steps_per_second': 4.52, 'epoch': 0.98}
{'train_runtime': 3209.5604, 'train_samples_per_second': 1.418, 'train_steps_per_second': 0.011, 'train_loss': 1.8933187757219587, 'epoch': 0.98}
Model Saved to  IA3_output/Meta-Llama-3-8B-Instruct/ultrafeedback
***** train metrics *****
  epoch                    =       0.98
  train_loss               =     1.8933
  train_runtime            = 0:53:29.56
  train_samples            =      20785
  train_samples_per_second =      1.418
  train_steps_per_second   =      0.011
