{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.880174291938998,
  "eval_steps": 500,
  "global_step": 175,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.14,
      "grad_norm": 0.17641697824001312,
      "learning_rate": 0.0009979871469976197,
      "loss": 7.4379,
      "step": 5
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1405138522386551,
      "learning_rate": 0.0009919647942993148,
      "loss": 7.3907,
      "step": 10
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.11540991067886353,
      "learning_rate": 0.0009819814303479266,
      "loss": 7.2494,
      "step": 15
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10370267182588577,
      "learning_rate": 0.0009681174353198686,
      "loss": 7.2126,
      "step": 20
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.09043771028518677,
      "learning_rate": 0.0009504844339512095,
      "loss": 7.137,
      "step": 25
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0864003375172615,
      "learning_rate": 0.000929224396800933,
      "loss": 6.8639,
      "step": 30
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.0865505263209343,
      "learning_rate": 0.0009045084971874737,
      "loss": 6.9622,
      "step": 35
    },
    {
      "epoch": 0.98,
      "eval_loss": 6.909733772277832,
      "eval_runtime": 51.8943,
      "eval_samples_per_second": 4.278,
      "eval_steps_per_second": 4.278,
      "step": 35
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.07496067881584167,
      "learning_rate": 0.0008765357330018055,
      "loss": 7.0283,
      "step": 40
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.06878803670406342,
      "learning_rate": 0.0008455313244934324,
      "loss": 6.8981,
      "step": 45
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.06674256175756454,
      "learning_rate": 0.0008117449009293668,
      "loss": 6.8285,
      "step": 50
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.06481508910655975,
      "learning_rate": 0.0007754484907260512,
      "loss": 6.9669,
      "step": 55
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.06531324982643127,
      "learning_rate": 0.0007369343312364993,
      "loss": 6.7556,
      "step": 60
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.07045511901378632,
      "learning_rate": 0.0006965125158269618,
      "loss": 6.7332,
      "step": 65
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.06481366604566574,
      "learning_rate": 0.0006545084971874737,
      "loss": 6.6341,
      "step": 70
    },
    {
      "epoch": 1.98,
      "eval_loss": 6.66782808303833,
      "eval_runtime": 51.8278,
      "eval_samples_per_second": 4.283,
      "eval_steps_per_second": 4.283,
      "step": 71
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.0746896043419838,
      "learning_rate": 0.0006112604669781572,
      "loss": 6.7893,
      "step": 75
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.07616498321294785,
      "learning_rate": 0.0005671166329088278,
      "loss": 6.6831,
      "step": 80
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.07804915308952332,
      "learning_rate": 0.0005224324151752575,
      "loss": 6.6369,
      "step": 85
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.08328896760940552,
      "learning_rate": 0.0004775675848247427,
      "loss": 6.6214,
      "step": 90
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.08959952741861343,
      "learning_rate": 0.0004328833670911724,
      "loss": 6.5871,
      "step": 95
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.09415937215089798,
      "learning_rate": 0.00038873953302184284,
      "loss": 6.6249,
      "step": 100
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.09639975428581238,
      "learning_rate": 0.00034549150281252633,
      "loss": 6.5567,
      "step": 105
    },
    {
      "epoch": 2.98,
      "eval_loss": 6.5022172927856445,
      "eval_runtime": 51.6557,
      "eval_samples_per_second": 4.298,
      "eval_steps_per_second": 4.298,
      "step": 107
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.09451094269752502,
      "learning_rate": 0.0003034874841730382,
      "loss": 6.6055,
      "step": 110
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.09859824180603027,
      "learning_rate": 0.0002630656687635007,
      "loss": 6.5759,
      "step": 115
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.09839928895235062,
      "learning_rate": 0.0002245515092739488,
      "loss": 6.5303,
      "step": 120
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.0970681682229042,
      "learning_rate": 0.00018825509907063325,
      "loss": 6.4276,
      "step": 125
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.10553817451000214,
      "learning_rate": 0.00015446867550656767,
      "loss": 6.5854,
      "step": 130
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.09929538518190384,
      "learning_rate": 0.00012346426699819457,
      "loss": 6.5392,
      "step": 135
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.09979729354381561,
      "learning_rate": 9.549150281252633e-05,
      "loss": 6.3659,
      "step": 140
    },
    {
      "epoch": 3.99,
      "eval_loss": 6.430356025695801,
      "eval_runtime": 51.7503,
      "eval_samples_per_second": 4.29,
      "eval_steps_per_second": 4.29,
      "step": 143
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.09806881099939346,
      "learning_rate": 7.077560319906695e-05,
      "loss": 6.4667,
      "step": 145
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.10190701484680176,
      "learning_rate": 4.9515566048790485e-05,
      "loss": 6.5899,
      "step": 150
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.1046876385807991,
      "learning_rate": 3.18825646801314e-05,
      "loss": 6.4474,
      "step": 155
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.09821328520774841,
      "learning_rate": 1.801856965207338e-05,
      "loss": 6.4773,
      "step": 160
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.10502330213785172,
      "learning_rate": 8.035205700685167e-06,
      "loss": 6.4376,
      "step": 165
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.10017609596252441,
      "learning_rate": 2.012853002380466e-06,
      "loss": 6.5072,
      "step": 170
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.10269572585821152,
      "learning_rate": 0.0,
      "loss": 6.4721,
      "step": 175
    },
    {
      "epoch": 4.88,
      "eval_loss": 6.423036098480225,
      "eval_runtime": 51.7248,
      "eval_samples_per_second": 4.292,
      "eval_steps_per_second": 4.292,
      "step": 175
    },
    {
      "epoch": 4.88,
      "step": 175,
      "total_flos": 2.1335405601226752e+18,
      "train_loss": 6.732171848842076,
      "train_runtime": 25596.4089,
      "train_samples_per_second": 0.897,
      "train_steps_per_second": 0.007
    }
  ],
  "logging_steps": 5,
  "max_steps": 175,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "total_flos": 2.1335405601226752e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
